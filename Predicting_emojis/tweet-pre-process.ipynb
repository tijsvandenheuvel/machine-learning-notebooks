{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# tweet data from txt to csv\n",
    "\n",
    "performance on my local machine\n",
    "- 800Mb takes 11 minutes\n",
    "- 200Mb takes 3 minutes\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-12-20 12:09:37.334349\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .getOrCreate()\n",
    "sc = ss.sparkContext\n",
    "s  = SQLContext(sc)\n",
    "\n",
    "t1 = datetime.now()\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = sc.textFile(\"./data/tweetstxt/test.txt\")\n",
    "tweets = sc.textFile(\"./data/tweetstxt/train.txt\")\n",
    "#tweets = sc.textFile(\"./data/tweetstxt/dev.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = tweets.flatMap(lambda x: x.split(' ')).filter(lambda x:x!='O').filter(lambda x:x!='').filter(lambda x:x!='<STOP>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = tweets_clean.collect()"
   ]
  },
  {
   "source": [
    "## list of words to list of tweets "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "global counter\n",
    "counter = -1\n",
    "\n",
    "def wordsToTweets(x):\n",
    "    global counter\n",
    "    if(x=='<START>'):\n",
    "        counter+=1\n",
    "        tweets.append('')\n",
    "    else:\n",
    "        tweets[counter]+=(x+\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tweet_list:\n",
    "    wordsToTweets(word)"
   ]
  },
  {
   "source": [
    "## list of tweets to data table (text,emoji)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_rdd = sc.parallelize(tweets)\n",
    "tweets = tweet_rdd.zipWithIndex().map(lambda x: (x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = tweets.map(lambda x: (x[0],re.sub(\":.*?:\",\"\",x[1])))\n",
    "emoji_rdd = tweets.map(lambda x: (x[0],re.findall(\":.*?:\",x[1])))\n",
    "emoji_rdd1 = emoji_rdd.map(lambda x:(x[0],x[1][0]))\n",
    "max_emoji = emoji_rdd.map(lambda x: len(x[1])).max()"
   ]
  },
  {
   "source": [
    "for i in range(1,max_emoji):\n",
    "    emoji_rdd2 = emoji_rdd.filter(lambda x:len(x[1])>i).map(lambda x: (x[0],x[1][i]))\n",
    "    if i==1:\n",
    "        emoji_rdd3 = emoji_rdd1.union(emoji_rdd2)\n",
    "    else:\n",
    "        emoji_rdd3 = emoji_rdd3.union(emoji_rdd2)\n",
    "\n",
    "rdd_for_df = text_rdd.leftOuterJoin(emoji_rdd3).map(lambda x:(x[1][0][:-1],x[1][1][1:-1]))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "source": [
    "## Write to file\n",
    "\n",
    "takes Â± 160 seconds for 200Mb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "df = s.createDataFrame(rdd_for_df, ['text','emoji']).distinct()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.csv('./data/test', sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:17:20.524952\n"
     ]
    }
   ],
   "source": [
    "duration = datetime.now()-t1\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}